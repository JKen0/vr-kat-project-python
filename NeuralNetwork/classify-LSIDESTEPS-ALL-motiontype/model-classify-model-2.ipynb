{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE']\n",
    "NUMBER_OF_FEATURES = CONFIG_DATA[\"NUMBER_OF_FEATURES\"]\n",
    "NUM_EPOCHS = CONFIG_DATA[\"NUMBER_OF_EPOCHS\"]\n",
    "CLASSICATIONS = CONFIG_DATA['CLASSES_MOTIONTYPE']\n",
    "\n",
    "ALL_X_TRAINING_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CLASSIFY-MOTIONTYPE-LSIDESTEPS-V0.npy'\n",
    "ALL_Y_TRAINING_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CLASSIFY-MOTIONTYPE-LSIDESTEPS-V0.npy'\n",
    "\n",
    "ALL_X_TEST_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-X-TEST-CLASSIFY-MOTIONTYPE-LSIDESTEPS-V0.npy'\n",
    "ALL_Y_TEST_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-Y-TEST-CLASSIFY-MOTIONTYPE-LSIDESTEPS-V0.npy'\n",
    "\n",
    "MOTION_MODEL_SAVE_PATH =  PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\models\\\\standard-backprop-motiontype-lsidesteps-2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.  -2.]\n",
      " [-12.  13.]\n",
      " [ -7.  10.]\n",
      " [ -7.   3.]\n",
      " [-12.  20.]\n",
      " [-19.  -5.]\n",
      " [  3.  14.]\n",
      " [ -7.  21.]\n",
      " [-11.  13.]\n",
      " [ -9.   2.]]\n",
      "[0 0 1 1 0 0 1 0 0 0]\n",
      "(86005, 2)\n",
      "(86005,)\n",
      "(21502, 2)\n",
      "(21502,)\n"
     ]
    }
   ],
   "source": [
    "ALL_X_TRAIN_DATA = np.load(ALL_X_TRAINING_DATA_PATH)\n",
    "ALL_Y_TRAIN_DATA = np.load(ALL_Y_TRAINING_DATA_PATH)\n",
    "\n",
    "ALL_X_TEST_DATA = np.load(ALL_X_TEST_DATA_PATH)\n",
    "ALL_Y_TEST_DATA = np.load(ALL_Y_TEST_DATA_PATH)\n",
    "\n",
    "ALL_X_TRAIN_DATA = ALL_X_TRAIN_DATA[:, [1, 5]]\n",
    "ALL_X_TEST_DATA = ALL_X_TEST_DATA[:, [1, 5]]\n",
    "\n",
    "ALL_X_COMBINED_DATA = np.concatenate((ALL_X_TRAIN_DATA, ALL_X_TEST_DATA))\n",
    "ALL_Y_COMBINED_DATA = np.concatenate((ALL_Y_TRAIN_DATA, ALL_Y_TEST_DATA))\n",
    "\n",
    "\n",
    "ALL_X_TRAIN_DATA, ALL_X_TEST_DATA, ALL_Y_TRAIN_DATA, ALL_Y_TEST_DATA = train_test_split(ALL_X_COMBINED_DATA, ALL_Y_COMBINED_DATA, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(ALL_X_TRAIN_DATA[:10])\n",
    "print(ALL_Y_TRAIN_DATA[:10])\n",
    "\n",
    "print(ALL_X_TRAIN_DATA.shape)\n",
    "print(ALL_Y_TRAIN_DATA.shape)\n",
    "\n",
    "print(ALL_X_TEST_DATA.shape)\n",
    "print(ALL_Y_TEST_DATA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random permutation indices\n",
    "random_indices_1 = np.random.permutation(len(ALL_X_TRAIN_DATA))\n",
    "\n",
    "\n",
    "# Shuffle the input features and target labels using the random indices\n",
    "shuffled_X_TRAIN_DATA = ALL_X_TRAIN_DATA[random_indices_1]\n",
    "shuffled_Y_TRAIN_DATA = ALL_Y_TRAIN_DATA[random_indices_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random permutation indices\n",
    "random_indices_2 = np.random.permutation(len(ALL_X_TEST_DATA))\n",
    "\n",
    "# Shuffle the input features and target labels using the random indices\n",
    "shuffled_X_TEST_DATA = ALL_X_TEST_DATA[random_indices_2]\n",
    "shuffled_Y_TEST_DATA = ALL_Y_TEST_DATA[random_indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_activation_function = 'sigmoid' if len(CLASSICATIONS) == 2 else 'softmax'\n",
    "loss_algorithm = 'binary_crossentropy' if len(CLASSICATIONS) == 2 else 'sparse_categorical_crossentropy'\n",
    "output_size = 1 if len(CLASSICATIONS) == 2 else len(CLASSICATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 24        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_motion = Sequential()\n",
    "model2_motion.add(InputLayer((2)))\n",
    "model2_motion.add(Dense(8, activation='relu'))\n",
    "model2_motion.add(Dense(4, activation='relu'))\n",
    "model2_motion.add(Dense(output_size, activation=output_activation_function))\n",
    "\n",
    "model2_motion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "2688/2688 [==============================] - 5s 2ms/step - loss: 0.5458 - acc: 0.7247 - val_loss: 0.3896 - val_acc: 0.8187\n",
      "Epoch 2/12\n",
      "2688/2688 [==============================] - 4s 1ms/step - loss: 0.3849 - acc: 0.8154 - val_loss: 0.3833 - val_acc: 0.8229\n",
      "Epoch 3/12\n",
      "2688/2688 [==============================] - 5s 2ms/step - loss: 0.3800 - acc: 0.8182 - val_loss: 0.3747 - val_acc: 0.8227\n",
      "Epoch 4/12\n",
      "2688/2688 [==============================] - 5s 2ms/step - loss: 0.3777 - acc: 0.8190 - val_loss: 0.3732 - val_acc: 0.8209\n",
      "Epoch 5/12\n",
      "2688/2688 [==============================] - 6s 2ms/step - loss: 0.3760 - acc: 0.8196 - val_loss: 0.3725 - val_acc: 0.8159\n",
      "Epoch 6/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3744 - acc: 0.8201 - val_loss: 0.3709 - val_acc: 0.8266\n",
      "Epoch 7/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3731 - acc: 0.8199 - val_loss: 0.3689 - val_acc: 0.8262\n",
      "Epoch 8/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3714 - acc: 0.8213 - val_loss: 0.3671 - val_acc: 0.8211\n",
      "Epoch 9/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3704 - acc: 0.8205 - val_loss: 0.3683 - val_acc: 0.8278\n",
      "Epoch 10/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3686 - acc: 0.8216 - val_loss: 0.3654 - val_acc: 0.8272\n",
      "Epoch 11/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3639 - acc: 0.8226 - val_loss: 0.3576 - val_acc: 0.8301\n",
      "Epoch 12/12\n",
      "2688/2688 [==============================] - 4s 2ms/step - loss: 0.3615 - acc: 0.8239 - val_loss: 0.3584 - val_acc: 0.8302\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model2_motion.compile(optimizer='adam', loss=loss_algorithm, metrics=['acc'])\n",
    "\n",
    "history2_motion = model2_motion.fit(shuffled_X_TRAIN_DATA, shuffled_Y_TRAIN_DATA, validation_data=(shuffled_X_TEST_DATA, shuffled_Y_TEST_DATA), epochs=NUM_EPOCHS)\n",
    "\n",
    "# Save the model to a file\n",
    "model2_motion.save(MOTION_MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_motiontype_lsidesteps = load_model(PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\models\\\\standard-backprop-motiontype-lsidesteps-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999993]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_motiontype_lsidesteps.predict(np.array([[11, -11]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
