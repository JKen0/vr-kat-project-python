{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "sys.path.append(PARENT_DIRECTORY + '//config/')\n",
    "from config import count_sequences_above_threshold, count_sequences_below_threshold, normalize_sensor_data\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE_SENSOR_DATA = CONFIG_DATA['NORMALIZE_SENSOR_DATA']\n",
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE_MOTION']\n",
    "NUMBER_OF_FEATURES = CONFIG_DATA['NUMBER_OF_FEATURES']\n",
    "\n",
    "CLASSIFICATIONS = CONFIG_DATA['CLASSES_MOTION']\n",
    "\n",
    "LABEL_COLUMN = 'Class_Motion'\n",
    "\n",
    "# processed data folder path\n",
    "DATA_FOLDER = PARENT_DIRECTORY + '\\\\processed-training-data\\\\4-PROCESSED-DATA\\TEST2\\\\'\n",
    "\n",
    "# numpy data folder\n",
    "NUMPY_DATA_FOLDER_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\'\n",
    "\n",
    "# v0 data (not normalized, use to generate more data)\n",
    "ALL_X_TEST_CLASSIFY_MOTION_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-X-TEST-CLASSIFY-MOTION-V0.npy'\n",
    "ALL_Y_TEST_CLASSIFY_MOTION_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-Y-TEST-CLASSIFY-MOTION-V0.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'STAND': 0, 'STEPS': 1, 'LSIDESTEPS': 2, 'RSIDESTEPS': 3}\n"
     ]
    }
   ],
   "source": [
    "LABEL_TO_CATEGORY = {label: category for category, label in enumerate(CLASSIFICATIONS)}\n",
    "\n",
    "print(LABEL_TO_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROC-TEST2-SIDESTEPS-L-LAR-140BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-L-LAR-35BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-L-LAR-70BPM.xlsx', 'PROC-TEST2-SIDESTEPS-L-SML-100BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-L-SML-25BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-L-SML-50BPM.xlsx', 'PROC-TEST2-SIDESTEPS-R-LAR-140BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-R-LAR-35BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-R-LAR-70BPM.xlsx', 'PROC-TEST2-SIDESTEPS-R-SML-100BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-R-SML-25BPM-AUGMENT.xlsx', 'PROC-TEST2-SIDESTEPS-R-SML-50BPM.xlsx', 'PROC-TEST2-STEPS-LR-LAR-130BPM.xlsx', 'PROC-TEST2-STEPS-LR-LAR-132BPM.xlsx', 'PROC-TEST2-STEPS-LR-LAR-180BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-184BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-196BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-260BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-264BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-45BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-46BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-49BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-65BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-66BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-LAR-90BPM.xlsx', 'PROC-TEST2-STEPS-LR-LAR-92BPM.xlsx', 'PROC-TEST2-STEPS-LR-LAR-98BPM.xlsx', 'PROC-TEST2-STEPS-LR-SML-100BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-130BPM.xlsx', 'PROC-TEST2-STEPS-LR-SML-180BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-25BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-260BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-45BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-50BPM.xlsx', 'PROC-TEST2-STEPS-LR-SML-65BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-90BPM.xlsx']\n"
     ]
    }
   ],
   "source": [
    "file_names = [file for file in os.listdir(DATA_FOLDER) if file.endswith('.xlsx') and os.path.isfile(os.path.join(DATA_FOLDER, file))]\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2Xy(df, windowSize=5):\n",
    "  X = []\n",
    "  y_Motion= []\n",
    "\n",
    "  # NORMALIZE THE SENSOR DATA\n",
    "  if NORMALIZE_SENSOR_DATA == True:\n",
    "    df[\"L_Pitch\"] = df[\"L_Pitch\"].apply(normalize_sensor_data)\n",
    "    df[\"L_Roll\"] = df[\"L_Roll\"].apply(normalize_sensor_data)\n",
    "    df[\"R_Pitch\"] = df[\"R_Pitch\"].apply(normalize_sensor_data)\n",
    "    df[\"R_Roll\"] = df[\"R_Roll\"].apply(normalize_sensor_data)\n",
    "    df[\"L_Pitch_Delta\"] = df[\"L_Pitch_Delta\"].apply(normalize_sensor_data)\n",
    "    df[\"L_Roll_Delta\"] = df[\"L_Roll_Delta\"].apply(normalize_sensor_data)\n",
    "    df[\"R_Pitch_Delta\"] = df[\"R_Pitch_Delta\"].apply(normalize_sensor_data)\n",
    "    df[\"R_Roll_Delta\"] = df[\"R_Roll_Delta\"].apply(normalize_sensor_data)\n",
    "\n",
    "  for i in range( len(df) - windowSize + 1):\n",
    "    # inputs: X rows\n",
    "    # form a new input which has size of our windowSize\n",
    "    input_data_list = []\n",
    "\n",
    "    # loop through each row in our windowsize\n",
    "    for j in range(windowSize):\n",
    "        # fetch sensor data for this row\n",
    "        row_values = df.loc[i + j, ['L_Pitch_Delta', 'L_Roll_Delta', 'R_Pitch_Delta', 'R_Roll_Delta']].values.tolist()\n",
    "\n",
    "        # add row values to the input\n",
    "        input_data_list.append(row_values)\n",
    "\n",
    "    # turnn list into array to do arthimetic\n",
    "    input_data_array = np.array(input_data_list)\n",
    "\n",
    "    # remove all negative sinces we want to the total change (we dont care which direction)\n",
    "    input_data_array = np.abs(input_data_array)\n",
    "\n",
    "    # calculate the total change for each sennsor value (TOTAL POSITIVE SENSOR CHANGES)\n",
    "    input_data_array = np.sum(input_data_array, axis=0)\n",
    "\n",
    "    if(np.isnan(input_data_array).any() == False):\n",
    "      # turn back to list\n",
    "      input_data_list = input_data_array.tolist()\n",
    "\n",
    "      # add our input to our total inputs, marked as X\n",
    "      X.append(input_data_list)\n",
    "\n",
    "      # outputs: y labels\n",
    "      label = df.loc[i + (windowSize - 1), [LABEL_COLUMN]].values.tolist()\n",
    "\n",
    "      y_Motion.append(label)\n",
    "\n",
    "  return (np.array(X), np.array(y_Motion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_X_MOTION = np.empty((0, NUMBER_OF_FEATURES))  # List to store all X training data\n",
    "ALL_Y_MOTION = np.empty((0))  # List to store all Y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(ALL_X_MOTION, ALL_Y_MOTION):\n",
    "    for fileName in file_names:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(DATA_FOLDER + fileName)\n",
    "\n",
    "        xTest, yTest_Motion = df2Xy(df, WINDOW_SIZE)\n",
    "\n",
    "        yTest_Motion = yTest_Motion.reshape(-1)\n",
    "        \n",
    "        ALL_X_MOTION = np.concatenate([ALL_X_MOTION, xTest])\n",
    "        ALL_Y_MOTION = np.concatenate([ALL_Y_MOTION, yTest_Motion])\n",
    "        \n",
    "        print('xTest.shape:', xTest.shape)\n",
    "        print('ALL_X.shape:', ALL_X_MOTION.shape, ' ALL_Y_MOTION.shape:', ALL_Y_MOTION.shape)\n",
    "        print('-------------------------------')\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(NUMPY_DATA_FOLDER_FILE_PATH):\n",
    "        os.makedirs(NUMPY_DATA_FOLDER_FILE_PATH)\n",
    "\n",
    "    # convert to numerical labels (originally text labels)\n",
    "    numerical_motion_label = np.vectorize(LABEL_TO_CATEGORY.get)(ALL_Y_MOTION)\n",
    "    \n",
    "\n",
    "    # Assuming your numpy array is called 'data_array'\n",
    "    np.save(ALL_X_TEST_CLASSIFY_MOTION_PATH, ALL_X_MOTION)\n",
    "    np.save(ALL_Y_TEST_CLASSIFY_MOTION_PATH, numerical_motion_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTest.shape: (3251, 4)\n",
      "ALL_X.shape: (3251, 4)  ALL_Y_MOTION.shape: (3251,)\n",
      "-------------------------------\n",
      "xTest.shape: (6512, 4)\n",
      "ALL_X.shape: (9763, 4)  ALL_Y_MOTION.shape: (9763,)\n",
      "-------------------------------\n",
      "xTest.shape: (3252, 4)\n",
      "ALL_X.shape: (13015, 4)  ALL_Y_MOTION.shape: (13015,)\n",
      "-------------------------------\n",
      "xTest.shape: (3862, 4)\n",
      "ALL_X.shape: (16877, 4)  ALL_Y_MOTION.shape: (16877,)\n",
      "-------------------------------\n",
      "xTest.shape: (7734, 4)\n",
      "ALL_X.shape: (24611, 4)  ALL_Y_MOTION.shape: (24611,)\n",
      "-------------------------------\n",
      "xTest.shape: (3863, 4)\n",
      "ALL_X.shape: (28474, 4)  ALL_Y_MOTION.shape: (28474,)\n",
      "-------------------------------\n",
      "xTest.shape: (3641, 4)\n",
      "ALL_X.shape: (32115, 4)  ALL_Y_MOTION.shape: (32115,)\n",
      "-------------------------------\n",
      "xTest.shape: (7292, 4)\n",
      "ALL_X.shape: (39407, 4)  ALL_Y_MOTION.shape: (39407,)\n",
      "-------------------------------\n",
      "xTest.shape: (3642, 4)\n",
      "ALL_X.shape: (43049, 4)  ALL_Y_MOTION.shape: (43049,)\n",
      "-------------------------------\n",
      "xTest.shape: (3600, 4)\n",
      "ALL_X.shape: (46649, 4)  ALL_Y_MOTION.shape: (46649,)\n",
      "-------------------------------\n",
      "xTest.shape: (7210, 4)\n",
      "ALL_X.shape: (53859, 4)  ALL_Y_MOTION.shape: (53859,)\n",
      "-------------------------------\n",
      "xTest.shape: (3601, 4)\n",
      "ALL_X.shape: (57460, 4)  ALL_Y_MOTION.shape: (57460,)\n",
      "-------------------------------\n",
      "xTest.shape: (3781, 4)\n",
      "ALL_X.shape: (61241, 4)  ALL_Y_MOTION.shape: (61241,)\n",
      "-------------------------------\n",
      "xTest.shape: (3628, 4)\n",
      "ALL_X.shape: (64869, 4)  ALL_Y_MOTION.shape: (64869,)\n",
      "-------------------------------\n",
      "xTest.shape: (3591, 4)\n",
      "ALL_X.shape: (68460, 4)  ALL_Y_MOTION.shape: (68460,)\n",
      "-------------------------------\n",
      "xTest.shape: (3497, 4)\n",
      "ALL_X.shape: (71957, 4)  ALL_Y_MOTION.shape: (71957,)\n",
      "-------------------------------\n",
      "xTest.shape: (3510, 4)\n",
      "ALL_X.shape: (75467, 4)  ALL_Y_MOTION.shape: (75467,)\n",
      "-------------------------------\n",
      "xTest.shape: (3780, 4)\n",
      "ALL_X.shape: (79247, 4)  ALL_Y_MOTION.shape: (79247,)\n",
      "-------------------------------\n",
      "xTest.shape: (3627, 4)\n",
      "ALL_X.shape: (82874, 4)  ALL_Y_MOTION.shape: (82874,)\n",
      "-------------------------------\n",
      "xTest.shape: (7192, 4)\n",
      "ALL_X.shape: (90066, 4)  ALL_Y_MOTION.shape: (90066,)\n",
      "-------------------------------\n",
      "xTest.shape: (7004, 4)\n",
      "ALL_X.shape: (97070, 4)  ALL_Y_MOTION.shape: (97070,)\n",
      "-------------------------------\n",
      "xTest.shape: (7030, 4)\n",
      "ALL_X.shape: (104100, 4)  ALL_Y_MOTION.shape: (104100,)\n",
      "-------------------------------\n",
      "xTest.shape: (7570, 4)\n",
      "ALL_X.shape: (111670, 4)  ALL_Y_MOTION.shape: (111670,)\n",
      "-------------------------------\n",
      "xTest.shape: (7264, 4)\n",
      "ALL_X.shape: (118934, 4)  ALL_Y_MOTION.shape: (118934,)\n",
      "-------------------------------\n",
      "xTest.shape: (3592, 4)\n",
      "ALL_X.shape: (122526, 4)  ALL_Y_MOTION.shape: (122526,)\n",
      "-------------------------------\n",
      "xTest.shape: (3498, 4)\n",
      "ALL_X.shape: (126024, 4)  ALL_Y_MOTION.shape: (126024,)\n",
      "-------------------------------\n",
      "xTest.shape: (3511, 4)\n",
      "ALL_X.shape: (129535, 4)  ALL_Y_MOTION.shape: (129535,)\n",
      "-------------------------------\n",
      "xTest.shape: (4939, 4)\n",
      "ALL_X.shape: (134474, 4)  ALL_Y_MOTION.shape: (134474,)\n",
      "-------------------------------\n",
      "xTest.shape: (3786, 4)\n",
      "ALL_X.shape: (138260, 4)  ALL_Y_MOTION.shape: (138260,)\n",
      "-------------------------------\n",
      "xTest.shape: (4558, 4)\n",
      "ALL_X.shape: (142818, 4)  ALL_Y_MOTION.shape: (142818,)\n",
      "-------------------------------\n",
      "xTest.shape: (9888, 4)\n",
      "ALL_X.shape: (152706, 4)  ALL_Y_MOTION.shape: (152706,)\n",
      "-------------------------------\n",
      "xTest.shape: (3785, 4)\n",
      "ALL_X.shape: (156491, 4)  ALL_Y_MOTION.shape: (156491,)\n",
      "-------------------------------\n",
      "xTest.shape: (9126, 4)\n",
      "ALL_X.shape: (165617, 4)  ALL_Y_MOTION.shape: (165617,)\n",
      "-------------------------------\n",
      "xTest.shape: (4940, 4)\n",
      "ALL_X.shape: (170557, 4)  ALL_Y_MOTION.shape: (170557,)\n",
      "-------------------------------\n",
      "xTest.shape: (7580, 4)\n",
      "ALL_X.shape: (178137, 4)  ALL_Y_MOTION.shape: (178137,)\n",
      "-------------------------------\n",
      "xTest.shape: (4559, 4)\n",
      "ALL_X.shape: (182696, 4)  ALL_Y_MOTION.shape: (182696,)\n",
      "-------------------------------\n",
      "(182696, 4)\n",
      "(182696,)\n"
     ]
    }
   ],
   "source": [
    "processData(ALL_X_MOTION, ALL_Y_MOTION)\n",
    "\n",
    "ALL_X_TEST_CLASSIFY_MOTION = np.load(ALL_X_TEST_CLASSIFY_MOTION_PATH)\n",
    "ALL_Y_TEST_CLASSIFY_MOTION = np.load(ALL_Y_TEST_CLASSIFY_MOTION_PATH)\n",
    "\n",
    "print(ALL_X_TEST_CLASSIFY_MOTION.shape)\n",
    "print(ALL_Y_TEST_CLASSIFY_MOTION.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(ALL_X_TEST_CLASSIFY_MOTION))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
