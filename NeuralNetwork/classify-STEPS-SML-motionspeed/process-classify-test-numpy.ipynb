{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "sys.path.append(PARENT_DIRECTORY + '//config/')\n",
    "from config import count_sequences_above_threshold, count_sequences_below_threshold, normalize_sensor_data\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE']\n",
    "NUMBER_OF_FEATURES = 8\n",
    "\n",
    "PITCH_THRESHOLD = CONFIG_DATA['SML_STEPS_PITCH_ROTATION_THRESHOLD']\n",
    "\n",
    "CLASSIFICATIONS = CONFIG_DATA['CLASSES_MOTIONSPEED']\n",
    "\n",
    "LABEL_COLUMN = 'Class_MotionSpeed'\n",
    "\n",
    "# processed data folder path\n",
    "DATA_FOLDER = PARENT_DIRECTORY + '\\\\processed-training-data\\\\4-PROCESSED-DATA\\\\TEST2\\\\'\n",
    "\n",
    "# save numpy data folder\n",
    "NUMPY_DATA_FOLDER_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\'\n",
    "\n",
    "# v0 data (not normalized, use to generate more data)\n",
    "ALL_X_TEST_CLASSIFY_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-X-TEST-CLASSIFY-MOTIONSPEED-SML-STEPS-V0.npy'\n",
    "ALL_Y_TEST_CLASSIFY_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-Y-TEST-CLASSIFY-MOTIONSPEED-SML-STEPS-V0.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SLOW': 0, 'AVERAGE': 1, 'FAST': 2}\n"
     ]
    }
   ],
   "source": [
    "LABEL_TO_CATEGORY = {label: category for category, label in enumerate(CLASSIFICATIONS)}\n",
    "\n",
    "print(LABEL_TO_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROC-TEST2-STEPS-LR-SML-100BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-130BPM.xlsx', 'PROC-TEST2-STEPS-LR-SML-180BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-25BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-260BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-45BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-50BPM.xlsx', 'PROC-TEST2-STEPS-LR-SML-65BPM-AUGMENT.xlsx', 'PROC-TEST2-STEPS-LR-SML-90BPM.xlsx']\n"
     ]
    }
   ],
   "source": [
    "file_names = [file for file in os.listdir(DATA_FOLDER) if file.endswith('.xlsx') and \"STEPS-LR-SML\" in file and \"STEPS\" in file and os.path.isfile(os.path.join(DATA_FOLDER, file))]\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2Xy(df, windowSize=5):\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  # NORMALIZE THE SENSOR DATA\n",
    "  #df[\"L_Pitch_Delta\"] = df[\"L_Pitch_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"L_Roll_Delta\"] = df[\"L_Roll_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"R_Pitch_Delta\"] = df[\"R_Pitch_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"R_Roll_Delta\"] = df[\"R_Roll_Delta\"].apply(normalizeSensorData)\n",
    "\n",
    "  for i in range( len(df) - windowSize + 1):\n",
    "    # inputs: X rows\n",
    "    # form a new input which has size of our windowSize\n",
    "    input_data_list_deltas = []\n",
    "    input_data_list_readings = []\n",
    "\n",
    "    # loop through each row in our windowsize\n",
    "    for j in range(windowSize):\n",
    "        # fetch sensor data for this row\n",
    "        row_values_deltas = df.loc[i + j, ['L_Pitch_Delta', 'L_Roll_Delta', 'R_Pitch_Delta', 'R_Roll_Delta']].values.tolist()\n",
    "        row_values_readings = df.loc[i + j, ['L_Pitch', 'L_Roll', 'R_Pitch', 'R_Roll']].values.tolist()\n",
    "\n",
    "        # add row values to the input\n",
    "        input_data_list_deltas.append(row_values_deltas)\n",
    "        input_data_list_readings.append(row_values_readings)\n",
    "\n",
    "    # turnn list into array to do arthimetic\n",
    "    raw_sensor_data = np.array(input_data_list_readings)\n",
    "    delta_sensor_data = np.array(input_data_list_deltas)\n",
    "\n",
    "    # remove all negative sinces we want to the total change (we dont care which direction)\n",
    "    input_calculate_deltas = np.abs(delta_sensor_data)\n",
    "\n",
    "    # calculate the total change for each sennsor value (TOTAL POSITIVE SENSOR CHANGES)\n",
    "    input_calculate_deltas = np.sum(input_calculate_deltas, axis=0)\n",
    "\n",
    "    # calculate total sequences\n",
    "    input_total_sequences = count_sequences_above_threshold(raw_sensor_data, PITCH_THRESHOLD)\n",
    "\n",
    "    input_data_array = np.concatenate((input_calculate_deltas, input_total_sequences))\n",
    "\n",
    "    if(np.isnan(input_data_array).any() == False):\n",
    "      # turn back to list\n",
    "      input_data_list = input_data_array.tolist()\n",
    "\n",
    "      # add our input to our total inputs, marked as X\n",
    "      X.append(input_data_list)\n",
    "\n",
    "      # outputs: y labels\n",
    "      label = df.loc[i + (windowSize - 1), [LABEL_COLUMN]].values.tolist()\n",
    "\n",
    "      y.append(label)\n",
    "\n",
    "  return (np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_X = np.empty((0, NUMBER_OF_FEATURES))  # List to store all X training data\n",
    "ALL_Y = np.empty((0))  # List to store all Y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(ALL_X, ALL_Y):\n",
    "    for fileName in file_names:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(DATA_FOLDER + fileName)\n",
    "\n",
    "        xTest, yTest = df2Xy(df, WINDOW_SIZE)\n",
    "\n",
    "        yTest = yTest.reshape(-1)\n",
    "        \n",
    "        ALL_X = np.concatenate([ALL_X, xTest])\n",
    "        ALL_Y = np.concatenate([ALL_Y, yTest])\n",
    "        \n",
    "        print('xTest.shape:', xTest.shape)\n",
    "        print('ALL_X.shape:', ALL_X.shape, ' ALL_Y.shape:', ALL_Y.shape)\n",
    "        print('-------------------------------')\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(NUMPY_DATA_FOLDER_FILE_PATH):\n",
    "        os.makedirs(NUMPY_DATA_FOLDER_FILE_PATH)\n",
    "\n",
    "    # convert to numerical labels (originally text labels)\n",
    "    numerical_label = np.vectorize(LABEL_TO_CATEGORY.get)(ALL_Y)\n",
    "    \n",
    "\n",
    "    # Assuming your numpy array is called 'data_array'\n",
    "    np.save(ALL_X_TEST_CLASSIFY_PATH, ALL_X)\n",
    "    np.save(ALL_Y_TEST_CLASSIFY_PATH, numerical_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTest.shape: (4929, 8)\n",
      "ALL_X.shape: (4929, 8)  ALL_Y.shape: (4929,)\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m processData(ALL_X, ALL_Y)\n\u001b[0;32m      3\u001b[0m ALL_X_TEST_CLASSIFY \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(ALL_X_TEST_CLASSIFY_PATH)\n\u001b[0;32m      4\u001b[0m ALL_Y_TEST_CLASSIFY \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(ALL_Y_TEST_CLASSIFY_PATH)\n",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m, in \u001b[0;36mprocessData\u001b[1;34m(ALL_X, ALL_Y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m fileName \u001b[39min\u001b[39;00m file_names:\n\u001b[0;32m      3\u001b[0m     \u001b[39m# Read the Excel file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(DATA_FOLDER \u001b[39m+\u001b[39m fileName)\n\u001b[1;32m----> 6\u001b[0m     xTest, yTest \u001b[39m=\u001b[39m df2Xy(df, WINDOW_SIZE)\n\u001b[0;32m      8\u001b[0m     yTest \u001b[39m=\u001b[39m yTest\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m     ALL_X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([ALL_X, xTest])\n",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m, in \u001b[0;36mdf2Xy\u001b[1;34m(df, windowSize)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# loop through each row in our windowsize\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(windowSize):\n\u001b[0;32m     19\u001b[0m     \u001b[39m# fetch sensor data for this row\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     row_values_deltas \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mloc[i \u001b[39m+\u001b[39;49m j, [\u001b[39m'\u001b[39;49m\u001b[39mL_Pitch_Delta\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mL_Roll_Delta\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mR_Pitch_Delta\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mR_Roll_Delta\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     21\u001b[0m     row_values_readings \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[i \u001b[39m+\u001b[39m j, [\u001b[39m'\u001b[39m\u001b[39mL_Pitch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mL_Roll\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mR_Pitch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mR_Roll\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     23\u001b[0m     \u001b[39m# add row values to the input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1280\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1279\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1282\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1000\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[0;32m    997\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m    998\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m    999\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m-> 1000\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m   1002\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m   1006\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1343\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1292\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4115\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   4110\u001b[0m         \u001b[39m# if we encounter an array-like and we only have 1 dim\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m         \u001b[39m# that means that their are list/ndarrays inside the Series!\u001b[39;00m\n\u001b[0;32m   4112\u001b[0m         \u001b[39m# so just return them (GH 6394)\u001b[39;00m\n\u001b[0;32m   4113\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n\u001b[1;32m-> 4115\u001b[0m     new_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mfast_xs(loc)\n\u001b[0;32m   4117\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced(\n\u001b[0;32m   4118\u001b[0m         new_mgr, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex[loc]\n\u001b[0;32m   4119\u001b[0m     )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[0;32m   4120\u001b[0m \u001b[39melif\u001b[39;00m is_scalar(loc):\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1074\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     result \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(result)\n\u001b[0;32m   1071\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m   1072\u001b[0m     \u001b[39m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m     \u001b[39m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[1;32m-> 1074\u001b[0m     \u001b[39mfor\u001b[39;00m i, rl \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(blk\u001b[39m.\u001b[39;49mmgr_locs):\n\u001b[0;32m   1075\u001b[0m         result[rl] \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39miget((i, loc))\n\u001b[0;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m immutable_ea:\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:205\u001b[0m, in \u001b[0;36mBlock.mgr_locs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value\n\u001b[0;32m    203\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m--> 205\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmgr_locs\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BlockPlacement:\n\u001b[0;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr_locs\n\u001b[0;32m    209\u001b[0m \u001b[39m@mgr_locs\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmgr_locs\u001b[39m(\u001b[39mself\u001b[39m, new_mgr_locs: BlockPlacement) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processData(ALL_X, ALL_Y)\n",
    "\n",
    "ALL_X_TEST_CLASSIFY = np.load(ALL_X_TEST_CLASSIFY_PATH)\n",
    "ALL_Y_TEST_CLASSIFY = np.load(ALL_Y_TEST_CLASSIFY_PATH)\n",
    "\n",
    "print(ALL_X_TEST_CLASSIFY.shape)\n",
    "print(ALL_Y_TEST_CLASSIFY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(ALL_X_TEST_CLASSIFY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
