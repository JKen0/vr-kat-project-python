{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE']\n",
    "NUMBER_OF_FEATURES = 4\n",
    "\n",
    "CLASSIFICATIONS = CONFIG_DATA['CLASSES_MOTIONTYPE']\n",
    "\n",
    "LABEL_COLUMN = 'Class_MotionType'\n",
    "\n",
    "# processed data folder path\n",
    "DATA_FOLDER = PARENT_DIRECTORY + '\\\\processed-training-data\\\\4-PROCESSED-DATA\\TRAIN2\\\\'\n",
    "\n",
    "# save numpy data folder\n",
    "NUMPY_DATA_FOLDER_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\'\n",
    "\n",
    "# v0 data (not normalized, use to generate more data)\n",
    "ALL_X_TRAIN_CLASSIFY_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CLASSIFY-MOTIONTYPE-STEPS-V0.npy'\n",
    "ALL_Y_TRAIN_CLASSIFY_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CLASSIFY-MOTIONTYPE-STEPS-V0.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAR': 0, 'SML': 1}\n"
     ]
    }
   ],
   "source": [
    "LABEL_TO_CATEGORY = {label: category for category, label in enumerate(CLASSIFICATIONS)}\n",
    "\n",
    "print(LABEL_TO_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROC-TRAIN2-STEPS-LR-LAR-100BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-110BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-112BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-124BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-164BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-196BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-200BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-224BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-31BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-41BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-49BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-50BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-56BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-60BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-62BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-80BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-82BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-98BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-110BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-60BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-80BPM.xlsx']\n"
     ]
    }
   ],
   "source": [
    "file_names = [file for file in os.listdir(DATA_FOLDER) if file.endswith('.xlsx') and \"SIDESTEPS\" not in file and \"STEPS\" in file and os.path.isfile(os.path.join(DATA_FOLDER, file))]\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSensorData(sensor_input):\n",
    "    return (sensor_input + 180)/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sequences_above_threshold(data, threshold):\n",
    "    num_sensors = data.shape[1]\n",
    "    counts = np.zeros(num_sensors, dtype=int)\n",
    "\n",
    "    for sensor_index in range(num_sensors):\n",
    "        count = 0\n",
    "        sequence_above_threshold = False\n",
    "\n",
    "        for value in data[:, sensor_index]:\n",
    "            if value > threshold:\n",
    "                if not sequence_above_threshold:\n",
    "                    count += 1\n",
    "                    sequence_above_threshold = True\n",
    "            else:\n",
    "                sequence_above_threshold = False\n",
    "\n",
    "        counts[sensor_index] = count\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2Xy(df, windowSize=5):\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  # NORMALIZE THE SENSOR DATA\n",
    "  #df[\"L_Pitch_Delta\"] = df[\"L_Pitch_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"L_Roll_Delta\"] = df[\"L_Roll_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"R_Pitch_Delta\"] = df[\"R_Pitch_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"R_Roll_Delta\"] = df[\"R_Roll_Delta\"].apply(normalizeSensorData)\n",
    "\n",
    "  for i in range( len(df) - windowSize + 1):\n",
    "    # inputs: X rows\n",
    "    # form a new input which has size of our windowSize\n",
    "    input_data_list_readings = []\n",
    "\n",
    "    # loop through each row in our windowsize\n",
    "    for j in range(windowSize):\n",
    "        # fetch sensor data for this row\n",
    "        row_values_readings = df.loc[i + j, ['L_Pitch', 'L_Roll', 'R_Pitch', 'R_Roll']].values.tolist()\n",
    "\n",
    "        # add row values to the input\n",
    "        input_data_list_readings.append(row_values_readings)\n",
    "\n",
    "    # turnn list into array to do arthimetic\n",
    "    raw_sensor_data = np.array(input_data_list_readings)\n",
    "\n",
    "    max_sensor_reading = np.max(raw_sensor_data, axis=0)\n",
    "\n",
    "    input_data_array = np.copy(max_sensor_reading)\n",
    "\n",
    "    if(np.isnan(input_data_array).any() == False):\n",
    "      # turn back to list\n",
    "      input_data_list = input_data_array.tolist()\n",
    "\n",
    "      # add our input to our total inputs, marked as X\n",
    "      X.append(input_data_list)\n",
    "\n",
    "      # outputs: y labels\n",
    "      label = df.loc[i + (windowSize - 1), [LABEL_COLUMN]].values.tolist()\n",
    "\n",
    "      y.append(label)\n",
    "\n",
    "  return (np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_X_TRAIN = np.empty((0, NUMBER_OF_FEATURES))  # List to store all X training data\n",
    "ALL_Y_TRAIN = np.empty((0))  # List to store all Y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(ALL_X, ALL_Y):\n",
    "    for fileName in file_names:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(DATA_FOLDER + fileName)\n",
    "\n",
    "        xTrain, yTrain = df2Xy(df, WINDOW_SIZE)\n",
    "\n",
    "        yTrain = yTrain.reshape(-1)\n",
    "        \n",
    "        ALL_X = np.concatenate([ALL_X, xTrain])\n",
    "        ALL_Y = np.concatenate([ALL_Y, yTrain])\n",
    "        \n",
    "        print('xTrain.shape:', xTrain.shape)\n",
    "        print('ALL_X_TRAIN.shape:', ALL_X.shape, ' ALL_Y_TRAIN.shape:', ALL_Y.shape)\n",
    "        print('-------------------------------')\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(NUMPY_DATA_FOLDER_FILE_PATH):\n",
    "        os.makedirs(NUMPY_DATA_FOLDER_FILE_PATH)\n",
    "\n",
    "    # convert to numerical labels (originally text labels)\n",
    "    numerical_label = np.vectorize(LABEL_TO_CATEGORY.get)(ALL_Y)\n",
    "\n",
    "    # Assuming your numpy array is called 'data_array'\n",
    "    np.save(ALL_X_TRAIN_CLASSIFY_PATH, ALL_X)\n",
    "    np.save(ALL_Y_TRAIN_CLASSIFY_PATH, numerical_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Classes_MotionType'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m processData(ALL_X_TRAIN, ALL_Y_TRAIN)\n\u001b[0;32m      3\u001b[0m ALL_X_TRAIN_CLASSIFY \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(ALL_X_TRAIN_CLASSIFY_PATH)\n\u001b[0;32m      4\u001b[0m ALL_Y_TRAIN_CLASSIFY \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(ALL_Y_TRAIN_CLASSIFY_PATH, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[50], line 6\u001b[0m, in \u001b[0;36mprocessData\u001b[1;34m(ALL_X, ALL_Y)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m fileName \u001b[39min\u001b[39;00m file_names:\n\u001b[0;32m      3\u001b[0m     \u001b[39m# Read the Excel file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(DATA_FOLDER \u001b[39m+\u001b[39m fileName)\n\u001b[1;32m----> 6\u001b[0m     xTrain, yTrain \u001b[39m=\u001b[39m df2Xy(df, WINDOW_SIZE)\n\u001b[0;32m      8\u001b[0m     yTrain \u001b[39m=\u001b[39m yTrain\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m     ALL_X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([ALL_X, xTrain])\n",
      "Cell \u001b[1;32mIn[48], line 39\u001b[0m, in \u001b[0;36mdf2Xy\u001b[1;34m(df, windowSize)\u001b[0m\n\u001b[0;32m     36\u001b[0m     X\u001b[39m.\u001b[39mappend(input_data_list)\n\u001b[0;32m     38\u001b[0m     \u001b[39m# outputs: y labels\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     label \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mloc[i \u001b[39m+\u001b[39;49m (windowSize \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m), [LABEL_COLUMN]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     41\u001b[0m     y\u001b[39m.\u001b[39mappend(label)\n\u001b[0;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m (np\u001b[39m.\u001b[39marray(X), np\u001b[39m.\u001b[39marray(y))\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1280\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1279\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1282\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1024\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1022\u001b[0m             \u001b[39mreturn\u001b[39;00m section\n\u001b[0;32m   1023\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m-> 1024\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[0;32m   1026\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1330\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1334\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1271\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1272\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1273\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1459\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1460\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1462\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1464\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kenne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Classes_MotionType'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "processData(ALL_X_TRAIN, ALL_Y_TRAIN)\n",
    "\n",
    "ALL_X_TRAIN_CLASSIFY = np.load(ALL_X_TRAIN_CLASSIFY_PATH)\n",
    "ALL_Y_TRAIN_CLASSIFY = np.load(ALL_Y_TRAIN_CLASSIFY_PATH, allow_pickle=True)\n",
    "\n",
    "print(ALL_X_TRAIN_CLASSIFY.shape)\n",
    "print(ALL_Y_TRAIN_CLASSIFY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(ALL_X_TRAIN_CLASSIFY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
