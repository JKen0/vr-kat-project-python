{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE']\n",
    "NUMBER_OF_FEATURES = 4\n",
    "\n",
    "CLASSIFICATIONS = CONFIG_DATA['CLASSES_MOTIONTYPE']\n",
    "\n",
    "LABEL_COLUMN = 'Class_MotionType'\n",
    "\n",
    "# processed data folder path\n",
    "DATA_FOLDER = PARENT_DIRECTORY + '\\\\processed-training-data\\\\4-PROCESSED-DATA\\TRAIN2\\\\'\n",
    "\n",
    "# save numpy data folder\n",
    "NUMPY_DATA_FOLDER_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\'\n",
    "\n",
    "# v0 data (not normalized, use to generate more data)\n",
    "ALL_X_TRAIN_CLASSIFY_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CLASSIFY-MOTIONTYPE-STEPS-V0.npy'\n",
    "ALL_Y_TRAIN_CLASSIFY_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CLASSIFY-MOTIONTYPE-STEPS-V0.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LAR': 0, 'SML': 1}\n"
     ]
    }
   ],
   "source": [
    "LABEL_TO_CATEGORY = {label: category for category, label in enumerate(CLASSIFICATIONS)}\n",
    "\n",
    "print(LABEL_TO_CATEGORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROC-TRAIN2-STEPS-LR-LAR-100BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-110BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-112BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-124BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-164BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-196BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-200BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-224BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-31BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-41BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-49BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-50BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-56BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-60BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-62BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-80BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-82BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-98BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-110BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-60BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-SML-80BPM.xlsx']\n"
     ]
    }
   ],
   "source": [
    "file_names = [file for file in os.listdir(DATA_FOLDER) if file.endswith('.xlsx') and \"SIDESTEPS\" not in file and \"STEPS\" in file and os.path.isfile(os.path.join(DATA_FOLDER, file))]\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSensorData(sensor_input):\n",
    "    return (sensor_input + 180)/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sequences_above_threshold(data, threshold):\n",
    "    num_sensors = data.shape[1]\n",
    "    counts = np.zeros(num_sensors, dtype=int)\n",
    "\n",
    "    for sensor_index in range(num_sensors):\n",
    "        count = 0\n",
    "        sequence_above_threshold = False\n",
    "\n",
    "        for value in data[:, sensor_index]:\n",
    "            if value > threshold:\n",
    "                if not sequence_above_threshold:\n",
    "                    count += 1\n",
    "                    sequence_above_threshold = True\n",
    "            else:\n",
    "                sequence_above_threshold = False\n",
    "\n",
    "        counts[sensor_index] = count\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2Xy(df, windowSize=5):\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  # NORMALIZE THE SENSOR DATA\n",
    "  #df[\"L_Pitch_Delta\"] = df[\"L_Pitch_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"L_Roll_Delta\"] = df[\"L_Roll_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"R_Pitch_Delta\"] = df[\"R_Pitch_Delta\"].apply(normalizeSensorData)\n",
    "  #df[\"R_Roll_Delta\"] = df[\"R_Roll_Delta\"].apply(normalizeSensorData)\n",
    "\n",
    "  for i in range( len(df) - windowSize + 1):\n",
    "    # inputs: X rows\n",
    "    # form a new input which has size of our windowSize\n",
    "    input_data_list_readings = []\n",
    "\n",
    "    # loop through each row in our windowsize\n",
    "    for j in range(windowSize):\n",
    "        # fetch sensor data for this row\n",
    "        row_values_readings = df.loc[i + j, ['L_Pitch', 'L_Roll', 'R_Pitch', 'R_Roll']].values.tolist()\n",
    "\n",
    "        # add row values to the input\n",
    "        input_data_list_readings.append(row_values_readings)\n",
    "\n",
    "    # turnn list into array to do arthimetic\n",
    "    raw_sensor_data = np.array(input_data_list_readings)\n",
    "\n",
    "    max_sensor_reading = np.max(raw_sensor_data, axis=0)\n",
    "\n",
    "    input_data_array = np.copy(max_sensor_reading)\n",
    "\n",
    "    if(np.isnan(input_data_array).any() == False):\n",
    "      # turn back to list\n",
    "      input_data_list = input_data_array.tolist()\n",
    "\n",
    "      # add our input to our total inputs, marked as X\n",
    "      X.append(input_data_list)\n",
    "\n",
    "      # outputs: y labels\n",
    "      label = df.loc[i + (windowSize - 1), [LABEL_COLUMN]].values.tolist()\n",
    "\n",
    "      y.append(label)\n",
    "\n",
    "  return (np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_X_TRAIN = np.empty((0, NUMBER_OF_FEATURES))  # List to store all X training data\n",
    "ALL_Y_TRAIN = np.empty((0))  # List to store all Y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(ALL_X, ALL_Y):\n",
    "    for fileName in file_names:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(DATA_FOLDER + fileName)\n",
    "\n",
    "        xTrain, yTrain = df2Xy(df, WINDOW_SIZE)\n",
    "\n",
    "        yTrain = yTrain.reshape(-1)\n",
    "        \n",
    "        ALL_X = np.concatenate([ALL_X, xTrain])\n",
    "        ALL_Y = np.concatenate([ALL_Y, yTrain])\n",
    "        \n",
    "        print('xTrain.shape:', xTrain.shape)\n",
    "        print('ALL_X_TRAIN.shape:', ALL_X.shape, ' ALL_Y_TRAIN.shape:', ALL_Y.shape)\n",
    "        print('-------------------------------')\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(NUMPY_DATA_FOLDER_FILE_PATH):\n",
    "        os.makedirs(NUMPY_DATA_FOLDER_FILE_PATH)\n",
    "\n",
    "    # convert to numerical labels (originally text labels)\n",
    "    numerical_label = np.vectorize(LABEL_TO_CATEGORY.get)(ALL_Y)\n",
    "\n",
    "    # Assuming your numpy array is called 'data_array'\n",
    "    np.save(ALL_X_TRAIN_CLASSIFY_PATH, ALL_X)\n",
    "    np.save(ALL_Y_TRAIN_CLASSIFY_PATH, numerical_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain.shape: (3381, 4)\n",
      "ALL_X_TRAIN.shape: (3381, 4)  ALL_Y_TRAIN.shape: (3381,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3274, 4)\n",
      "ALL_X_TRAIN.shape: (6655, 4)  ALL_Y_TRAIN.shape: (6655,)\n",
      "-------------------------------\n",
      "xTrain.shape: (4560, 4)\n",
      "ALL_X_TRAIN.shape: (11215, 4)  ALL_Y_TRAIN.shape: (11215,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3773, 4)\n",
      "ALL_X_TRAIN.shape: (14988, 4)  ALL_Y_TRAIN.shape: (14988,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3181, 4)\n",
      "ALL_X_TRAIN.shape: (18169, 4)  ALL_Y_TRAIN.shape: (18169,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3072, 4)\n",
      "ALL_X_TRAIN.shape: (21241, 4)  ALL_Y_TRAIN.shape: (21241,)\n",
      "-------------------------------\n",
      "xTrain.shape: (4505, 4)\n",
      "ALL_X_TRAIN.shape: (25746, 4)  ALL_Y_TRAIN.shape: (25746,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3796, 4)\n",
      "ALL_X_TRAIN.shape: (29542, 4)  ALL_Y_TRAIN.shape: (29542,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3381, 4)\n",
      "ALL_X_TRAIN.shape: (32923, 4)  ALL_Y_TRAIN.shape: (32923,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3274, 4)\n",
      "ALL_X_TRAIN.shape: (36197, 4)  ALL_Y_TRAIN.shape: (36197,)\n",
      "-------------------------------\n",
      "xTrain.shape: (4560, 4)\n",
      "ALL_X_TRAIN.shape: (40757, 4)  ALL_Y_TRAIN.shape: (40757,)\n",
      "-------------------------------\n",
      "xTrain.shape: (7565, 4)\n",
      "ALL_X_TRAIN.shape: (48322, 4)  ALL_Y_TRAIN.shape: (48322,)\n",
      "-------------------------------\n",
      "xTrain.shape: (6382, 4)\n",
      "ALL_X_TRAIN.shape: (54704, 4)  ALL_Y_TRAIN.shape: (54704,)\n",
      "-------------------------------\n",
      "xTrain.shape: (6164, 4)\n",
      "ALL_X_TRAIN.shape: (60868, 4)  ALL_Y_TRAIN.shape: (60868,)\n",
      "-------------------------------\n",
      "xTrain.shape: (9030, 4)\n",
      "ALL_X_TRAIN.shape: (69898, 4)  ALL_Y_TRAIN.shape: (69898,)\n",
      "-------------------------------\n",
      "xTrain.shape: (7613, 4)\n",
      "ALL_X_TRAIN.shape: (77511, 4)  ALL_Y_TRAIN.shape: (77511,)\n",
      "-------------------------------\n",
      "xTrain.shape: (6782, 4)\n",
      "ALL_X_TRAIN.shape: (84293, 4)  ALL_Y_TRAIN.shape: (84293,)\n",
      "-------------------------------\n",
      "xTrain.shape: (6568, 4)\n",
      "ALL_X_TRAIN.shape: (90861, 4)  ALL_Y_TRAIN.shape: (90861,)\n",
      "-------------------------------\n",
      "xTrain.shape: (9140, 4)\n",
      "ALL_X_TRAIN.shape: (100001, 4)  ALL_Y_TRAIN.shape: (100001,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3773, 4)\n",
      "ALL_X_TRAIN.shape: (103774, 4)  ALL_Y_TRAIN.shape: (103774,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3181, 4)\n",
      "ALL_X_TRAIN.shape: (106955, 4)  ALL_Y_TRAIN.shape: (106955,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3072, 4)\n",
      "ALL_X_TRAIN.shape: (110027, 4)  ALL_Y_TRAIN.shape: (110027,)\n",
      "-------------------------------\n",
      "xTrain.shape: (4505, 4)\n",
      "ALL_X_TRAIN.shape: (114532, 4)  ALL_Y_TRAIN.shape: (114532,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3796, 4)\n",
      "ALL_X_TRAIN.shape: (118328, 4)  ALL_Y_TRAIN.shape: (118328,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3997, 4)\n",
      "ALL_X_TRAIN.shape: (122325, 4)  ALL_Y_TRAIN.shape: (122325,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3286, 4)\n",
      "ALL_X_TRAIN.shape: (125611, 4)  ALL_Y_TRAIN.shape: (125611,)\n",
      "-------------------------------\n",
      "xTrain.shape: (4351, 4)\n",
      "ALL_X_TRAIN.shape: (129962, 4)  ALL_Y_TRAIN.shape: (129962,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3997, 4)\n",
      "ALL_X_TRAIN.shape: (133959, 4)  ALL_Y_TRAIN.shape: (133959,)\n",
      "-------------------------------\n",
      "xTrain.shape: (6591, 4)\n",
      "ALL_X_TRAIN.shape: (140550, 4)  ALL_Y_TRAIN.shape: (140550,)\n",
      "-------------------------------\n",
      "xTrain.shape: (8721, 4)\n",
      "ALL_X_TRAIN.shape: (149271, 4)  ALL_Y_TRAIN.shape: (149271,)\n",
      "-------------------------------\n",
      "xTrain.shape: (8013, 4)\n",
      "ALL_X_TRAIN.shape: (157284, 4)  ALL_Y_TRAIN.shape: (157284,)\n",
      "-------------------------------\n",
      "xTrain.shape: (3286, 4)\n",
      "ALL_X_TRAIN.shape: (160570, 4)  ALL_Y_TRAIN.shape: (160570,)\n",
      "-------------------------------\n",
      "xTrain.shape: (4351, 4)\n",
      "ALL_X_TRAIN.shape: (164921, 4)  ALL_Y_TRAIN.shape: (164921,)\n",
      "-------------------------------\n",
      "(164921, 4)\n",
      "(164921,)\n"
     ]
    }
   ],
   "source": [
    "processData(ALL_X_TRAIN, ALL_Y_TRAIN)\n",
    "\n",
    "ALL_X_TRAIN_CLASSIFY = np.load(ALL_X_TRAIN_CLASSIFY_PATH)\n",
    "ALL_Y_TRAIN_CLASSIFY = np.load(ALL_Y_TRAIN_CLASSIFY_PATH, allow_pickle=True)\n",
    "\n",
    "print(ALL_X_TRAIN_CLASSIFY.shape)\n",
    "print(ALL_Y_TRAIN_CLASSIFY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(ALL_X_TRAIN_CLASSIFY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
