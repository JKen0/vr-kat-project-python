{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE']\n",
    "NUMBER_OF_FEATURES = CONFIG_DATA[\"NUMBER_OF_FEATURES\"]\n",
    "NUM_EPOCHS = CONFIG_DATA[\"NUMBER_OF_EPOCHS\"]\n",
    "CLASSICATIONS = CONFIG_DATA['CLASSES_MOTIONSPEED']\n",
    "\n",
    "ALL_X_TRAINING_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CLASSIFY-MOTIONSPEED-LAR-LSIDESTEPS-V0.npy'\n",
    "ALL_Y_TRAINING_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CLASSIFY-MOTIONSPEED-LAR-LSIDESTEPS-V0.npy'\n",
    "\n",
    "ALL_X_TEST_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-X-TEST-CLASSIFY-MOTIONSPEED-LAR-LSIDESTEPS-V0.npy'\n",
    "ALL_Y_TEST_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-Y-TEST-CLASSIFY-MOTIONSPEED-LAR-LSIDESTEPS-V0.npy'\n",
    "\n",
    "MOTION_MODEL_SAVE_PATH =  PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\models\\\\standard-backprop-motionspeed-lar-lsidesteps-2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "(52979, 2)\n",
      "(52979,)\n",
      "(13245, 2)\n",
      "(13245,)\n"
     ]
    }
   ],
   "source": [
    "ALL_X_TRAIN_DATA = np.load(ALL_X_TRAINING_DATA_PATH)\n",
    "ALL_Y_TRAIN_DATA = np.load(ALL_Y_TRAINING_DATA_PATH)\n",
    "\n",
    "ALL_X_TEST_DATA = np.load(ALL_X_TEST_DATA_PATH)\n",
    "ALL_Y_TEST_DATA = np.load(ALL_Y_TEST_DATA_PATH)\n",
    "\n",
    "ALL_X_TRAIN_DATA = ALL_X_TRAIN_DATA[:, [1, 5]]\n",
    "ALL_X_TEST_DATA = ALL_X_TEST_DATA[:, [1, 5]]\n",
    "\n",
    "\n",
    "ALL_X_COMBINED_DATA = np.concatenate((ALL_X_TRAIN_DATA, ALL_X_TEST_DATA))\n",
    "ALL_Y_COMBINED_DATA = np.concatenate((ALL_Y_TRAIN_DATA - 1, ALL_Y_TEST_DATA - 1))\n",
    "\n",
    "print(ALL_Y_TEST_DATA[:500])\n",
    "\n",
    "\n",
    "ALL_X_TRAIN_DATA, ALL_X_TEST_DATA, ALL_Y_TRAIN_DATA, ALL_Y_TEST_DATA = train_test_split(ALL_X_COMBINED_DATA, ALL_Y_COMBINED_DATA, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(ALL_X_TRAIN_DATA.shape)\n",
    "print(ALL_Y_TRAIN_DATA.shape)\n",
    "\n",
    "print(ALL_X_TEST_DATA.shape)\n",
    "print(ALL_Y_TEST_DATA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random permutation indices\n",
    "random_indices_1 = np.random.permutation(len(ALL_X_TRAIN_DATA))\n",
    "\n",
    "\n",
    "# Shuffle the input features and target labels using the random indices\n",
    "shuffled_X_TRAIN_DATA = ALL_X_TRAIN_DATA[random_indices_1]\n",
    "shuffled_Y_TRAIN_DATA = ALL_Y_TRAIN_DATA[random_indices_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random permutation indices\n",
    "random_indices_2 = np.random.permutation(len(ALL_X_TEST_DATA))\n",
    "\n",
    "# Shuffle the input features and target labels using the random indices\n",
    "shuffled_X_TEST_DATA = ALL_X_TEST_DATA[random_indices_2]\n",
    "shuffled_Y_TEST_DATA = ALL_Y_TEST_DATA[random_indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_activation_function = 'sigmoid' if len(CLASSICATIONS) == 3 else 'softmax'\n",
    "loss_algorithm = 'binary_crossentropy' if len(CLASSICATIONS) == 3 else 'sparse_categorical_crossentropy'\n",
    "output_size = 1 if len(CLASSICATIONS) == 3 else len(CLASSICATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 24        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 5         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_motion = Sequential()\n",
    "model2_motion.add(InputLayer((2)))\n",
    "model2_motion.add(Dense(8, activation='relu'))\n",
    "model2_motion.add(Dense(4, activation='relu'))\n",
    "model2_motion.add(Dense(output_size, activation=output_activation_function))\n",
    "\n",
    "model2_motion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1656/1656 [==============================] - 3s 1ms/step - loss: -3.3397 - acc: 0.3786 - val_loss: -15.4120 - val_acc: 0.3824\n",
      "Epoch 2/12\n",
      "1656/1656 [==============================] - 2s 1ms/step - loss: -88.2678 - acc: 0.3786 - val_loss: -208.5373 - val_acc: 0.3824\n",
      "Epoch 3/12\n",
      "1656/1656 [==============================] - 2s 1ms/step - loss: -439.0386 - acc: 0.3786 - val_loss: -734.3286 - val_acc: 0.3824\n",
      "Epoch 4/12\n",
      " 669/1656 [===========>..................] - ETA: 1s - loss: -898.2483 - acc: 0.3791"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model2_motion.compile(optimizer='adam', loss=loss_algorithm, metrics=['acc'])\n",
    "\n",
    "history2_motion = model2_motion.fit(shuffled_X_TRAIN_DATA, shuffled_Y_TRAIN_DATA, validation_data=(shuffled_X_TEST_DATA, shuffled_Y_TEST_DATA), epochs=NUM_EPOCHS)\n",
    "\n",
    "# Save the model to a file\n",
    "model2_motion.save(MOTION_MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
