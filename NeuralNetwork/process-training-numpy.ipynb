{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 10\n",
    "NUMBER_OF_FEATURES = 6\n",
    "NUMBER_OF_CLASSES = 2\n",
    "\n",
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "\n",
    "DATA_FOLDER = PARENT_DIRECTORY + '\\\\processed-training-data\\\\4-PROCESSED-DATA\\TRAIN2\\\\'\n",
    "\n",
    "# numpy data folder\n",
    "NUMPY_DATA_FOLDER_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\'\n",
    "\n",
    "\n",
    "# v0 data (not normalized, use to generate more data)\n",
    "ALL_X_TRAIN_CURRVEL_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CURRVEL-V0.npy'\n",
    "ALL_Y_TRAIN_CURRVEL_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CURRVEL-V0.npy'\n",
    "ALL_X_TRAIN_ALLVEL_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-ALLVEL-V0.npy'\n",
    "ALL_Y_TRAIN_ALLVEL_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-ALLVEL-V0.npy'\n",
    "\n",
    "# v1 data (0-1 normalized data)\n",
    "ALL_X_TRAIN_CURRVEL_NORM1_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CURRVEL-V1.npy'\n",
    "ALL_Y_TRAIN_CURRVEL_NORM1_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CURRVEL-V1.npy'\n",
    "ALL_X_TRAIN_ALLVEL_NORM1_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-ALLVEL-V1.npy'\n",
    "ALL_Y_TRAIN_ALLVEL_NORM1_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-ALLVEL-V1.npy'\n",
    "\n",
    "# v2 data (only 4 features, normalized data)\n",
    "ALL_X_TRAIN_NOVEL_NORM_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-NOVEL-V2.npy'\n",
    "ALL_Y_TRAIN_NOVEL_NORM_FILE_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-NOVEL-V2.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROC-TRAIN2-SIDESTEPS-L-LAR-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-LAR-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-LAR-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-LAR-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-LAR-60BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-LAR-80BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-MED-110BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-MED-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-MED-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-MED-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-MED-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-L-MED-80BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-LAR-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-LAR-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-LAR-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-LAR-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-LAR-60BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-LAR-80BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-MED-110BPM.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-MED-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-MED-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-MED-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-MED-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-SIDESTEPS-R-MED-80BPM.xlsx', 'PROC-TRAIN2-STAND1.xlsx', 'PROC-TRAIN2-STAND2.xlsx', 'PROC-TRAIN2-STAND3.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-100BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-110BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-200BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-50BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-60BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-LAR-80BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-100BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-110BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-120BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-160BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-200BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-220BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-30BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-40BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-50BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-55BPM-AUGMENT.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-60BPM.xlsx', 'PROC-TRAIN2-STEPS-LR-MED-80BPM.xlsx']\n"
     ]
    }
   ],
   "source": [
    "file_names = [file for file in os.listdir(DATA_FOLDER) if file.endswith('.xlsx') and os.path.isfile(os.path.join(DATA_FOLDER, file))]\n",
    "\n",
    "# TEMP LIMITER REMOVE WHEN READY\n",
    "#file_names = [file_names[20]]\n",
    "\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeSensorData(sensor_input):\n",
    "    if(sensor_input < 0):\n",
    "        return np.abs(sensor_input/360)\n",
    "    else:\n",
    "        return 0.5 + np.abs(sensor_input/360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2Xy(df, windowSize=5, fetchAllSpeed=False):\n",
    "  X, y = [], []\n",
    "\n",
    "\n",
    "  for i in range( len(df) - windowSize ):\n",
    "    # inputs: X rows\n",
    "    # form a new input which has size of our windowSize\n",
    "    input = []\n",
    "\n",
    "    # loop through each row in our windowsize\n",
    "    for j in range(windowSize):\n",
    "        # fetch sensor data for this row\n",
    "        row_values = df.loc[i + j, ['L_Pitch', 'L_Roll', 'R_Pitch', 'R_Roll']].values.tolist()\n",
    "        \n",
    "        # If j is the last element, fetch X_Vel and Z_Vel\n",
    "        if (j == windowSize - 1) or (fetchAllSpeed == True):\n",
    "            row_values.extend(df.loc[i + j, ['X_Vel', 'Z_Vel']].values.tolist())\n",
    "        else:\n",
    "            # Fill columns 5 and 6 with zeros\n",
    "            row_values.extend([0.0, 0.0])\n",
    "\n",
    "        # add row values to the input\n",
    "        input.append(row_values)\n",
    "\n",
    "    # add our input to our total inputs, marked as X\n",
    "    X.append(input)\n",
    "\n",
    "\n",
    "    # outputs: y labels\n",
    "    label = df.loc[i + windowSize, ['X_Vel', 'Z_Vel']].values.tolist()\n",
    "\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "  return (np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_X_TRAIN_CURRVEL = np.empty((0, WINDOW_SIZE, NUMBER_OF_FEATURES))  # List to store all X training data\n",
    "ALL_Y_TRAIN_CURRVEL = np.empty((0, NUMBER_OF_CLASSES))  # List to store all Y training data\n",
    "\n",
    "ALL_X_TRAIN_ALLVEL = np.empty((0, WINDOW_SIZE, NUMBER_OF_FEATURES))  # List to store all X training data\n",
    "ALL_Y_TRAIN_ALLVEL = np.empty((0, NUMBER_OF_CLASSES))  # List to store all Y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(ALL_X_TRAIN_CURRVEL, ALL_Y_TRAIN_CURRVEL, ALL_X_TRAIN_ALLVEL, ALL_Y_TRAIN_ALLVEL, NUMPY_DATA_FOLDER_FILE_PATH):\n",
    "    for fileName in file_names:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(DATA_FOLDER + fileName)\n",
    "\n",
    "        # NORMALIZE THE SENSOR DATA\n",
    "        df[\"L_Pitch\"] = df[\"L_Pitch\"].apply(normalizeSensorData)\n",
    "        df[\"L_Roll\"] = df[\"L_Roll\"].apply(normalizeSensorData)\n",
    "        df[\"R_Pitch\"] = df[\"R_Pitch\"].apply(normalizeSensorData)\n",
    "        df[\"R_Roll\"] = df[\"R_Roll\"].apply(normalizeSensorData)\n",
    "\n",
    "        xTrain_CurrVel, yTrain_CurrVel = df2Xy(df, WINDOW_SIZE, False)\n",
    "        xTrain_AllVel, yTrain_AllVel = df2Xy(df, WINDOW_SIZE, True)\n",
    "\n",
    "        ALL_X_TRAIN_CURRVEL = np.concatenate([ALL_X_TRAIN_CURRVEL, xTrain_CurrVel])\n",
    "        ALL_Y_TRAIN_CURRVEL = np.concatenate([ALL_Y_TRAIN_CURRVEL, yTrain_CurrVel])\n",
    "\n",
    "        ALL_X_TRAIN_ALLVEL = np.concatenate([ALL_X_TRAIN_ALLVEL, xTrain_AllVel])\n",
    "        ALL_Y_TRAIN_ALLVEL = np.concatenate([ALL_Y_TRAIN_ALLVEL, yTrain_AllVel])\n",
    "\n",
    "        \n",
    "        print('xTrain_CurrVel.shape:', xTrain_CurrVel.shape, ' xTrain_CurrVel.shape:', xTrain_CurrVel.shape)\n",
    "        print('ALL_X_TRAIN_CURRVEL.shape:', ALL_X_TRAIN_CURRVEL.shape, ' ALL_Y_TRAIN_CURRVEL.shape:', ALL_Y_TRAIN_CURRVEL.shape)\n",
    "        print('-------------------------------')\n",
    "\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(NUMPY_DATA_FOLDER_FILE_PATH):\n",
    "        os.makedirs(NUMPY_DATA_FOLDER_FILE_PATH)\n",
    "\n",
    "    # Assuming your numpy array is called 'data_array'\n",
    "    np.save(ALL_X_TRAIN_CURRVEL_FILE_PATH, ALL_X_TRAIN_CURRVEL)\n",
    "    np.save(ALL_Y_TRAIN_CURRVEL_FILE_PATH, ALL_Y_TRAIN_CURRVEL)\n",
    "    np.save(ALL_X_TRAIN_ALLVEL_FILE_PATH, ALL_X_TRAIN_ALLVEL)\n",
    "    np.save(ALL_Y_TRAIN_ALLVEL_FILE_PATH, ALL_Y_TRAIN_ALLVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229679, 10, 6)\n",
      "(229679, 2)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(ALL_X_TRAIN_CURRVEL_FILE_PATH):\n",
    "    processData(ALL_X_TRAIN_CURRVEL, ALL_Y_TRAIN_CURRVEL, ALL_X_TRAIN_ALLVEL, ALL_Y_TRAIN_ALLVEL, NUMPY_DATA_FOLDER_FILE_PATH)\n",
    "\n",
    "ALL_X_TRAIN_CURRVEL = np.load(ALL_X_TRAIN_CURRVEL_FILE_PATH)\n",
    "ALL_Y_TRAIN_CURRVEL = np.load(ALL_Y_TRAIN_CURRVEL_FILE_PATH)\n",
    "ALL_X_TRAIN_ALLVEL = np.load(ALL_X_TRAIN_ALLVEL_FILE_PATH)\n",
    "ALL_Y_TRAIN_ALLVEL = np.load(ALL_Y_TRAIN_ALLVEL_FILE_PATH)\n",
    "\n",
    "print(ALL_X_TRAIN_CURRVEL.shape)\n",
    "print(ALL_Y_TRAIN_CURRVEL.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume the range is from -8 to 8\n",
    "def normalizeXVelocity(velocity_input):\n",
    "    return ((velocity_input + 8)/16)\n",
    "\n",
    "# assume thhe range from 0 to 8\n",
    "def normalizeZVelocity(velocity_input):\n",
    "    return np.abs(velocity_input/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given we have non normalize velocity, lets normalize velocity and hold it in our V1 data. \n",
    "ALL_X_TRAIN_CURRVEL_CURR_NORM1 = np.copy(ALL_X_TRAIN_CURRVEL)\n",
    "ALL_Y_TRAIN_CURRVEL_CURR_NORM1 = np.copy(ALL_Y_TRAIN_CURRVEL)\n",
    "ALL_X_TRAIN_CURRVEL_ALLVEL_NORM1 = np.copy(ALL_X_TRAIN_ALLVEL)\n",
    "ALL_Y_TRAIN_CURRVEL_ALLVEL_NORM1 = np.copy(ALL_Y_TRAIN_ALLVEL)\n",
    "\n",
    "#loop through each data training data\n",
    "for i in range(ALL_X_TRAIN_CURRVEL_CURR_NORM1.shape[0]):\n",
    "    #loop through each row in our WINDOW_SIZE\n",
    "    for j in range(ALL_X_TRAIN_CURRVEL_CURR_NORM1.shape[1]):\n",
    "\n",
    "        #normalize X annd Z velocity using our function\n",
    "        #index 4 of X - X Velocity\n",
    "        #index 5 of X - Z Velocity\n",
    "        ALL_X_TRAIN_CURRVEL_CURR_NORM1[i,j,4] = normalizeXVelocity(ALL_X_TRAIN_CURRVEL_CURR_NORM1[i,j,4])\n",
    "        ALL_X_TRAIN_CURRVEL_CURR_NORM1[i,j,5] = normalizeZVelocity(ALL_X_TRAIN_CURRVEL_CURR_NORM1[i,j,5])\n",
    "\n",
    "        #index 0 of Y - X Velocity\n",
    "        #index 1 of Y - Z Velocity\n",
    "        ALL_Y_TRAIN_CURRVEL_CURR_NORM1[i,0] = normalizeXVelocity(ALL_Y_TRAIN_CURRVEL_CURR_NORM1[i,0])\n",
    "        ALL_Y_TRAIN_CURRVEL_CURR_NORM1[i,1] = normalizeZVelocity( ALL_Y_TRAIN_CURRVEL_CURR_NORM1[i,1])\n",
    "\n",
    "        ALL_X_TRAIN_CURRVEL_ALLVEL_NORM1[i,j,4] = normalizeXVelocity(ALL_X_TRAIN_CURRVEL_ALLVEL_NORM1[i,j,4])\n",
    "        ALL_X_TRAIN_CURRVEL_ALLVEL_NORM1[i,j,5] = normalizeZVelocity(ALL_X_TRAIN_CURRVEL_ALLVEL_NORM1[i,j,5])\n",
    "\n",
    "        ALL_Y_TRAIN_CURRVEL_ALLVEL_NORM1[i,0] = normalizeXVelocity(ALL_Y_TRAIN_CURRVEL_ALLVEL_NORM1[i,0])\n",
    "        ALL_Y_TRAIN_CURRVEL_ALLVEL_NORM1[i,1] = normalizeZVelocity( ALL_Y_TRAIN_CURRVEL_ALLVEL_NORM1[i,1])\n",
    "\n",
    "\n",
    "# Assuming your numpy array is called 'data_array'\n",
    "np.save(ALL_X_TRAIN_CURRVEL_NORM1_FILE_PATH, ALL_X_TRAIN_CURRVEL_CURR_NORM1)\n",
    "np.save(ALL_Y_TRAIN_CURRVEL_NORM1_FILE_PATH, ALL_Y_TRAIN_CURRVEL_CURR_NORM1)\n",
    "np.save(ALL_X_TRAIN_ALLVEL_NORM1_FILE_PATH, ALL_X_TRAIN_CURRVEL_ALLVEL_NORM1)\n",
    "np.save(ALL_Y_TRAIN_ALLVEL_NORM1_FILE_PATH, ALL_Y_TRAIN_CURRVEL_ALLVEL_NORM1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_X_TRAIN_CURRVEL_NORM = np.load(ALL_X_TRAIN_CURRVEL_NORM1_FILE_PATH)\n",
    "ALL_Y_TRAIN_CURRVEL_NORM = np.load(ALL_Y_TRAIN_CURRVEL_NORM1_FILE_PATH)\n",
    "\n",
    "ALL_X_TRAIN_NOVEL = ALL_X_TRAIN_CURRVEL_NORM[:, :, :4]\n",
    "\n",
    "np.save(ALL_X_TRAIN_NOVEL_NORM_FILE_PATH, ALL_X_TRAIN_NOVEL)\n",
    "np.save(ALL_Y_TRAIN_NOVEL_NORM_FILE_PATH, ALL_Y_TRAIN_CURRVEL_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
