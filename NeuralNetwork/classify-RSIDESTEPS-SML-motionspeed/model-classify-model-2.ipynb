{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Flatten\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "# Get the parent directory\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_DIRECTORY)\n",
    "PARENT_DIRECTORY = os.path.dirname(PARENT_DIRECTORY)\n",
    "\n",
    "# Open the config file and load its content into a dictionary\n",
    "config_file = open(PARENT_DIRECTORY + '\\\\config\\\\config.json')\n",
    "CONFIG_DATA = json.load(config_file)\n",
    "\n",
    "# Close the file after loading the data\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = CONFIG_DATA['WINDOW_SIZE']\n",
    "NUMBER_OF_FEATURES = CONFIG_DATA[\"NUMBER_OF_FEATURES\"]\n",
    "NUM_EPOCHS = CONFIG_DATA[\"NUMBER_OF_EPOCHS\"]\n",
    "CLASSICATIONS = CONFIG_DATA['CLASSES_MOTIONSPEED']\n",
    "\n",
    "ALL_X_TRAINING_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-X-TRAIN-CLASSIFY-MOTIONSPEED-SML-RSIDESTEPS-V0.npy'\n",
    "ALL_Y_TRAINING_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\training\\\\ALL-Y-TRAIN-CLASSIFY-MOTIONSPEED-SML-RSIDESTEPS-V0.npy'\n",
    "\n",
    "ALL_X_TEST_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-X-TEST-CLASSIFY-MOTIONSPEED-SML-RSIDESTEPS-V0.npy'\n",
    "ALL_Y_TEST_DATA_PATH = PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\np-saved-data\\\\test\\\\ALL-Y-TEST-CLASSIFY-MOTIONSPEED-SML-RSIDESTEPS-V0.npy'\n",
    "\n",
    "MOTION_MODEL_SAVE_PATH =  PARENT_DIRECTORY + '\\\\NeuralNetwork\\\\models\\\\standard-backprop-motionspeed-sml-rsidesteps-2.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0]\n",
      "(32175,)\n",
      "(32175,)\n",
      "(8044,)\n",
      "(8044,)\n"
     ]
    }
   ],
   "source": [
    "ALL_X_TRAIN_DATA = np.load(ALL_X_TRAINING_DATA_PATH)\n",
    "ALL_Y_TRAIN_DATA = np.load(ALL_Y_TRAINING_DATA_PATH)\n",
    "\n",
    "ALL_X_TEST_DATA = np.load(ALL_X_TEST_DATA_PATH)\n",
    "ALL_Y_TEST_DATA = np.load(ALL_Y_TEST_DATA_PATH)\n",
    "\n",
    "ALL_X_TRAIN_DATA = ALL_X_TRAIN_DATA[:, 7] + ALL_X_TRAIN_DATA[:, 11]\n",
    "\n",
    "# Keep column index 3 and concatenate it with the sum_7_and_11 array\n",
    "ALL_X_TEST_DATA = ALL_X_TEST_DATA[:, 7] + ALL_X_TEST_DATA[:, 11]\n",
    "\n",
    "ALL_X_COMBINED_DATA = np.concatenate((ALL_X_TRAIN_DATA, ALL_X_TEST_DATA))\n",
    "ALL_Y_COMBINED_DATA = np.concatenate((ALL_Y_TRAIN_DATA -1 , ALL_Y_TEST_DATA -1))\n",
    "\n",
    "ALL_X_TRAIN_DATA, ALL_X_TEST_DATA, ALL_Y_TRAIN_DATA, ALL_Y_TEST_DATA = train_test_split(ALL_X_COMBINED_DATA, ALL_Y_COMBINED_DATA, test_size=0.2, random_state=42)\n",
    "\n",
    "print(ALL_Y_TRAIN_DATA[:100])\n",
    "\n",
    "print(ALL_X_TRAIN_DATA.shape)\n",
    "print(ALL_Y_TRAIN_DATA.shape)\n",
    "\n",
    "print(ALL_X_TEST_DATA.shape)\n",
    "print(ALL_Y_TEST_DATA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random permutation indices\n",
    "random_indices_1 = np.random.permutation(len(ALL_X_TRAIN_DATA))\n",
    "\n",
    "\n",
    "# Shuffle the input features and target labels using the random indices\n",
    "shuffled_X_TRAIN_DATA = ALL_X_TRAIN_DATA[random_indices_1]\n",
    "shuffled_Y_TRAIN_DATA = ALL_Y_TRAIN_DATA[random_indices_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random permutation indices\n",
    "random_indices_2 = np.random.permutation(len(ALL_X_TEST_DATA))\n",
    "\n",
    "# Shuffle the input features and target labels using the random indices\n",
    "shuffled_X_TEST_DATA = ALL_X_TEST_DATA[random_indices_2]\n",
    "shuffled_Y_TEST_DATA = ALL_Y_TEST_DATA[random_indices_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_activation_function = 'sigmoid' if len(CLASSICATIONS) == 3 else 'softmax'\n",
    "loss_algorithm = 'binary_crossentropy' if len(CLASSICATIONS) == 3 else 'sparse_categorical_crossentropy'\n",
    "output_size = 1 if len(CLASSICATIONS) == 3 else len(CLASSICATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 8)                 16        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_motion = Sequential()\n",
    "model2_motion.add(InputLayer((1)))\n",
    "model2_motion.add(Dense(8, activation='relu'))\n",
    "model2_motion.add(Dense(8, activation='relu'))\n",
    "model2_motion.add(Dense(output_size, activation=output_activation_function))\n",
    "\n",
    "model2_motion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006/1006 [==============================] - 2s 1ms/step - loss: 0.6281 - acc: 0.6774 - val_loss: 0.6179 - val_acc: 0.6866\n",
      "Epoch 2/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6092 - acc: 0.6974 - val_loss: 0.6097 - val_acc: 0.6969\n",
      "Epoch 3/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6043 - acc: 0.7026 - val_loss: 0.6073 - val_acc: 0.6969\n",
      "Epoch 4/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6027 - acc: 0.7023 - val_loss: 0.6063 - val_acc: 0.6969\n",
      "Epoch 5/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6019 - acc: 0.7025 - val_loss: 0.6063 - val_acc: 0.6969\n",
      "Epoch 6/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6013 - acc: 0.7023 - val_loss: 0.6054 - val_acc: 0.6969\n",
      "Epoch 7/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6016 - acc: 0.7021 - val_loss: 0.6052 - val_acc: 0.6969\n",
      "Epoch 8/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6015 - acc: 0.7023 - val_loss: 0.6065 - val_acc: 0.6969\n",
      "Epoch 9/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6013 - acc: 0.7020 - val_loss: 0.6050 - val_acc: 0.6969\n",
      "Epoch 10/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6015 - acc: 0.7023 - val_loss: 0.6050 - val_acc: 0.6969\n",
      "Epoch 11/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6017 - acc: 0.7025 - val_loss: 0.6054 - val_acc: 0.6969\n",
      "Epoch 12/12\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6015 - acc: 0.7026 - val_loss: 0.6056 - val_acc: 0.6969\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model2_motion.compile(optimizer='adam', loss=loss_algorithm, metrics=['acc'])\n",
    "\n",
    "history2_motion = model2_motion.fit(shuffled_X_TRAIN_DATA, shuffled_Y_TRAIN_DATA, validation_data=(shuffled_X_TEST_DATA, shuffled_Y_TEST_DATA), epochs=NUM_EPOCHS)\n",
    "\n",
    "# Save the model to a file\n",
    "model2_motion.save(MOTION_MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
